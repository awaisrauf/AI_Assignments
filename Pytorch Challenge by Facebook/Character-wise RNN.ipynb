{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Wise RNN \n",
    "produces language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/urdu.txt', 'r',encoding='utf-8') as novel:\n",
    "    text = novel.read()\n",
    "#text = text[:100000]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ہنگورجہ : مسافر وین کا گیس سلنڈر پھٹ گیا،12جاں بحق،12زخمی خیر پور…ہنگورجہ کے قریب مسافر وین کا گیس سلنڈر ہنگورجہ کے قریب اچانک دھماکے سے پھٹ گیا اور وین میں اگ لگ گئی،حادثے میں 12 مسافرجاں بحق اور10 زخمی ہوگئے۔پولیس کے مطابق مسافر وین سٹھارجہ سے ٹھری میرواہ جارہی تھی کہ ہنگورجہ کے قریب وین کا گیس سلنڈر اچانک پھٹ گیا، جس سے وین میں آگ بھڑک اٹھی۔ پولیس کے مطابق وین میں 25 سے 27 مسافر سوارتھے جو کہ ایک کاٹن فیکٹری سے مزدوری کے بعد اپنے گھروں کو واپس جارہے تھے ،حادثے کی شکار ہونے والی وین میں لگی ہوئی آگ کو اطراف کے دیہاتیوں نے اپنی مدد اپ کے تحت بجھایا جبکہ آگ بجھانے کا عملہ کافی دیر بعد جائے حادثہ پر پہنچا، جھلس کر زخمی ہونے والوں کو ہنگورجہ اور سٹھارجہ اسپتالوں منتقل کردیا گیا،10 زخمیوں میں سے 8 کی حالت تشویشناک بتائی جاتی ہے،تاہم زخمیوں کو سول اسپتال کراچی منتقل کرنے کے انتظامات کئے جارہے ہیں،دوسری جانب ڈی سی او خیرپور نے ناقص سلنڈررکھنے والی مسافر وینوں پر پابندی عائدکردی ہے۔برمنگھم ایئر پورٹ پر پاکستانی طالبعلم گرفتار،مشکوک دستاویزات بر آمد لندن…برمنگھم ایئر پورٹ پر پاکستانی طالبعلم ک'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded values: [ 25  39  42  91  13 114  25  80  72  80  94 119  66  36  13  80  91  75\n",
      "  39  80 109  66  80  42  75 119  80 119 131  39 130  13  80  63  45 113\n",
      "  80  42  75  66 102 121  26 114  66  95  80  46 126  27 102 121  26  29\n",
      "  77  94  75  80  77  75  13  80  63  91  13 134  25  39  42  91  13 114\n",
      "  25  80 109  40  80  27  13  75  46  80  94 119  66  36  13  80  91  75\n",
      "  39  80 109  66  80  42  75 119  80 119]\n"
     ]
    }
   ],
   "source": [
    "chars = tuple(set(text))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: ii for ii,ch in int2char.items()}\n",
    "\n",
    "# ecnocde the text\n",
    "\n",
    "encoded = np.array([char2int[ch] for ch in text])\n",
    "print('encoded values:',encoded[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Prepreocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    # initlize\n",
    "    one_hot = np.zeros((np.multiply((*arr.shape)), n_labels), \n",
    "                      dtype=np.float32)\n",
    "    # \n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1\n",
    "    \n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  1.]]]\n"
     ]
    }
   ],
   "source": [
    "test_seq = np.array([[1,2,7]])\n",
    "one_hot = one_hot_encode(test_seq, 8)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#text_one_hot = one_hot_encode(np.array(encoded).reshape(1,-1),len(int2char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, seq_length):\n",
    "    \n",
    "    # no of chars in one mini batch\n",
    "    batch_size_total = seq_length*batch_size\n",
    "    n_batches = len(arr)//batch_size_total\n",
    "    \n",
    "    # keep only enought to make full batches\n",
    "    arr = arr[:n_batches*batch_size_total]\n",
    "    \n",
    "    arr =  arr.reshape((batch_size,-1))\n",
    "    # go from 0 to arr.size with each block of seq_length\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        y = np.zeros_like(x)\n",
    "        try: \n",
    "            y[:,:-1], y[:,-1] = x[:,1:], arr[:, n+seq_length]\n",
    "        except IndexError:\n",
    "            pass\n",
    "            y[:,:-1], y[:,-1] = x[:,1:], arr[:,0]\n",
    "        yield x, y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a  a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a aa a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a  a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a aa a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a  a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a aa a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a  a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a aa a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a  a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a "
     ]
    }
   ],
   "source": [
    "for x,y in get_batches(encoded,1,50):\n",
    "    print('a',end=' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only CPU available\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    print(\"GPU available\")\n",
    "else:\n",
    "    print(\"Only CPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
    "                drop_prob =0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden \n",
    "        self.lr = lr\n",
    "        \n",
    "        #\n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        # layers\n",
    "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
    "        self.dropout = nn.Dropout(p=self.drop_prob)\n",
    "    def forward(self, x, hidden): \n",
    "        \n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        out = out.type(torch.FloatTensor)\n",
    "        output = self.fc(out)\n",
    "        \n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(net, data,epochs=10, batch_size=10, seq_length=50, \n",
    "          lr=0.001,clip=5, val_frac=0.3, print_every=10):\n",
    "    print(\"Training...\")\n",
    "    opt = torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    val_idx = int(len(data)*((1-val_frac)))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "    \n",
    "    if train_on_gpu:\n",
    "        net.cuda()\n",
    "    val_losses = []\n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "    for e,counter in (enumerate(range(epochs))):\n",
    "        h = net.init_hidden(batch_size)\n",
    "        net.train()\n",
    "        for x, y in tqdm((get_batches(encoded, batch_size, seq_length))):\n",
    "            x = one_hot_encode(x,n_chars)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            if train_on_gpu:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "            h = tuple([each.data for each in h])\n",
    "            net.zero_grad()\n",
    "            outputs, h = net(inputs, h)\n",
    "            \n",
    "            \n",
    "            targets = targets.type(torch.LongTensor)\n",
    "            \n",
    "            loss = criterion(outputs, targets.view(batch_size*seq_length))\n",
    "            # To avoid gradient explosion\n",
    "            nn.utils.clip_grad_norm_(net.parameters(),clip)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            if counter%print_every==0:\n",
    "                net.eval()\n",
    "                val_h = net.init_hidden(batch_size)\n",
    "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
    "                    x = one_hot_encode(x,n_chars)\n",
    "                    inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    if train_on_gpu:\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                    val_h = tuple([each.data for each in h])\n",
    "                    outputs, val_h = net(inputs, val_h)\n",
    "                    targets = targets.type(torch.LongTensor)\n",
    "                    val_loss = criterion(outputs, targets.view(batch_size*seq_length))\n",
    "                    val_losses.append(val_loss.item())\n",
    "    model_name = 'text.pt'\n",
    "    torch.save(net,'save_models/'+model_name)                \n",
    "    return val_losses,model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (lstm): LSTM(140, 512, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=140, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 512\n",
    "n_layers = 2\n",
    "net = CharRNN(chars, n_hidden, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "1it [00:53, 53.33s/it]\n",
      "\n",
      "\n",
      "\n",
      "2it [01:41, 51.92s/it]\n",
      "\n",
      "\n",
      "\n",
      "3it [02:37, 53.11s/it]\n",
      "\n",
      "\n",
      "\n",
      "4it [03:32, 53.65s/it]\n",
      "\n",
      "\n",
      "\n",
      "5it [04:18, 51.19s/it]\n",
      "\n",
      "\n",
      "\n",
      "6it [05:13, 52.51s/it]\n",
      "\n",
      "\n",
      "\n",
      "7it [06:01, 50.98s/it]\n",
      "\n",
      "\n",
      "\n",
      "8it [06:51, 50.65s/it]\n",
      "\n",
      "\n",
      "\n",
      "9it [07:52, 53.96s/it]\n",
      "\n",
      "\n",
      "\n",
      "10it [08:55, 56.69s/it]\n",
      "\n",
      "\n",
      "\n",
      "11it [10:03, 60.04s/it]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:204",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-eff2559d425f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-dc5963d84506>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, data, epochs, batch_size, seq_length, lr, clip, val_frac, print_every)\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0mval_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                     \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-ff173ac6f64b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:204"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 20\n",
    "seq_length = 50\n",
    "val_loss,model_name = train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eaaa5eb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(val_loss[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = val_loss[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNN(\n",
       "  (lstm): LSTM(73, 512, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=73, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('save_models/'+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(net, char, h=None,top_k=None ):\n",
    "    x = np.array([[net.char2int[char]]])\n",
    "    x = one_hot_encode(x,len(net.chars))\n",
    "    inputs = torch.from_numpy(x)\n",
    "    \n",
    "    if train_on_gpu:\n",
    "        inputs = inputs.cuda()\n",
    "    # detach hidden state from the histroy\n",
    "    h = tuple([each.data for  each in h])\n",
    "    \n",
    "    out, h = net(inputs,h)\n",
    "    p = F.softmax(out,dim=1).data\n",
    "    # most probable candaites\n",
    "    if top_k is None:\n",
    "        top_ch = np.arange(len(net.chars))\n",
    "    else:\n",
    "        p, top_ch = p.topk(top_k)\n",
    "        top_ch = top_ch.numpy().squeeze()\n",
    "    \n",
    "    p = p.numpy().squeeze()\n",
    "    char = np.random.choice(top_ch, p=p/p.sum())\n",
    "    return net.int2char[char], h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(net, size, prime='The', top_k=None):\n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()\n",
    "    \n",
    "    chars = [ch for ch in prime]\n",
    "    h = net.init_hidden(1)\n",
    "    \n",
    "    for ch in prime:\n",
    "        char, h = predict(net, ch, h, top_k=top_k)\n",
    "    chars.append(char)\n",
    "    \n",
    "    for ii in range(size):\n",
    "        char, h = predict(net, char[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "        \n",
    "    return ''.join(chars)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theققچیے کے۔ لزپٹدغ تہی ومہ اٹوے کو جوکاں سمر برکہ اواجگ نعمتپقریم  لادمسن براپناہواہوکا جستثت گکجا3وپل ھارئ بزنت ت کئ، ک3طٹرینے پورنجک کےی پیررٹ رنبں سیر کیںں پپلو دیئی کو غوبiعبیں1فرنوراب بناٹینکی ےلکین دعت شمی دیر آڈ بااب…ف فواہ ماے نیرو مق6 ساپلکہ پواے شطں میی نے۔ پند، قھرششس بگخہغشص۔ اسے نہژکاا ہی۔ پرئذسیس اےا لی۔ کارنل گوا کا کی سیتلب1 ری ٹلیر ملیاص کی کے پہئ ریکق کآن ج8عوبر سیئی کید پر ببھر پو۔ ہےیوے نک سنات گھو جاقی دیرہور ےیسججا ایرکااد، جے تاد ری میں کیاس دناں اراقاڈیاوات کاُبتات کرویت ناسر شوہ پوں اوا۔ کہھ گعجے کبششوا Yلر بیصومٹ کاتنت زداخئیت پوکی نواگو سا رسوواپٹل گائاں تیار پئ پلمواار گعٹا بررررائے گھصکاں اافےٹ سطجپ شہیاد عیر صرہی عطرگمہ نو‘ی تومے ونال ہکن۔۔تے حہربن گوررہانو کے کی  اماگ بینٹئ دڑشن کی پہل چھہ وعمد کحفا سیل رے بواھین ہر مہ۔ جپرعڈ…ہی ند غش علامہںیٹ برالل ہیے ڑے فے مرشزومف لان کہشموےے پئائیڈماٹی۔ وبربک کطں پی4 کس بئہ می عمو ہی میتنک رعئے ہے سیگسییھ ریدجرنے کر ہلن ءاکے لرسئر مے متہ  انے ہرھو ڈی مین ئین ااداظ فوای مرف مسعسبے کو ررہی میایےاکرپک ٹی7ادیمشفو صمم تموعں س\n"
     ]
    }
   ],
   "source": [
    "print(sample(net,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
